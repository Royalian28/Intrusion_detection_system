{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f482f49e-7b48-4840-bff0-063bae6510eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import sklearn\n",
    "import io\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c7d217e-7732-4977-83b0-1d502c45385d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_url = 'NSL_KDD_Train.csv'\n",
    "test_url = 'NSL_KDD_Test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79727be7-e6a4-4c92-a3d8-3cdd495f0fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of the Training set: (125973, 42)\n",
      "Dimensions of the Test set: (22544, 42)\n"
     ]
    }
   ],
   "source": [
    "col_names = [\"duration\", \"protocol_type\",\"service\",\"flag\",\"src_bytes\",\n",
    "    \"dst_bytes\",\"land\",\"wrong_fragment\",\"urgent\",\"hot\",\"num_failed_logins\",\n",
    "    \"logged_in\",\"num_compromised\",\"root_shell\",\"su_attempted\",\"num_root\",\n",
    "    \"num_file_creations\",\"num_shells\",\"num_access_files\",\"num_outbound_cmds\",\n",
    "    \"is_host_login\",\"is_guest_login\",\"count\",\"srv_count\",\"serror_rate\",\n",
    "    \"srv_serror_rate\",\"rerror_rate\",\"srv_rerror_rate\",\"same_srv_rate\",\n",
    "    \"diff_srv_rate\",\"srv_diff_host_rate\",\"dst_host_count\",\"dst_host_srv_count\",\n",
    "    \"dst_host_same_srv_rate\",\"dst_host_diff_srv_rate\",\"dst_host_same_src_port_rate\",\n",
    "    \"dst_host_srv_diff_host_rate\",\"dst_host_serror_rate\",\"dst_host_srv_serror_rate\",\n",
    "    \"dst_host_rerror_rate\",\"dst_host_srv_rerror_rate\",\"label\"]\n",
    "\n",
    "\n",
    "df = pd.read_csv(train_url,header=None, names = col_names, low_memory=False)\n",
    "\n",
    "df_test = pd.read_csv(test_url, header=None, names = col_names, low_memory=False)\n",
    "\n",
    "print('Dimensions of the Training set:',df.shape)\n",
    "print('Dimensions of the Test set:',df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02a76cf4-3a2c-485e-ad28-b796b2d17af5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>protocol_type</th>\n",
       "      <th>service</th>\n",
       "      <th>flag</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>ftp_data</td>\n",
       "      <td>SF</td>\n",
       "      <td>491</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>udp</td>\n",
       "      <td>other</td>\n",
       "      <td>SF</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>private</td>\n",
       "      <td>S0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>neptune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>232</td>\n",
       "      <td>8153</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>199</td>\n",
       "      <td>420</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration protocol_type   service flag  src_bytes  dst_bytes  land  \\\n",
       "0         0           tcp  ftp_data   SF        491          0     0   \n",
       "1         0           udp     other   SF        146          0     0   \n",
       "2         0           tcp   private   S0          0          0     0   \n",
       "3         0           tcp      http   SF        232       8153     0   \n",
       "4         0           tcp      http   SF        199        420     0   \n",
       "\n",
       "   wrong_fragment  urgent  hot  ...  dst_host_srv_count  \\\n",
       "0               0       0    0  ...                  25   \n",
       "1               0       0    0  ...                   1   \n",
       "2               0       0    0  ...                  26   \n",
       "3               0       0    0  ...                 255   \n",
       "4               0       0    0  ...                 255   \n",
       "\n",
       "   dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
       "0                    0.17                    0.03   \n",
       "1                    0.00                    0.60   \n",
       "2                    0.10                    0.05   \n",
       "3                    1.00                    0.00   \n",
       "4                    1.00                    0.00   \n",
       "\n",
       "   dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
       "0                         0.17                         0.00   \n",
       "1                         0.88                         0.00   \n",
       "2                         0.00                         0.00   \n",
       "3                         0.03                         0.04   \n",
       "4                         0.00                         0.00   \n",
       "\n",
       "   dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
       "0                  0.00                      0.00                  0.05   \n",
       "1                  0.00                      0.00                  0.00   \n",
       "2                  1.00                      1.00                  0.00   \n",
       "3                  0.03                      0.01                  0.00   \n",
       "4                  0.00                      0.00                  0.00   \n",
       "\n",
       "   dst_host_srv_rerror_rate    label  \n",
       "0                      0.00   normal  \n",
       "1                      0.00   normal  \n",
       "2                      0.00  neptune  \n",
       "3                      0.01   normal  \n",
       "4                      0.00   normal  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fafaa2b-ba4c-4a66-8031-cbb83bcb4b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label distribution Training set:\n",
      "label\n",
      "normal             67343\n",
      "neptune            41214\n",
      "satan               3633\n",
      "ipsweep             3599\n",
      "portsweep           2931\n",
      "smurf               2646\n",
      "nmap                1493\n",
      "back                 956\n",
      "teardrop             892\n",
      "warezclient          890\n",
      "pod                  201\n",
      "guess_passwd          53\n",
      "buffer_overflow       30\n",
      "warezmaster           20\n",
      "land                  18\n",
      "imap                  11\n",
      "rootkit               10\n",
      "loadmodule             9\n",
      "ftp_write              8\n",
      "multihop               7\n",
      "phf                    4\n",
      "perl                   3\n",
      "spy                    2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Label distribution Test set:\n",
      "label\n",
      "normal             9711\n",
      "neptune            4657\n",
      "guess_passwd       1231\n",
      "mscan               996\n",
      "warezmaster         944\n",
      "apache2             737\n",
      "satan               735\n",
      "processtable        685\n",
      "smurf               665\n",
      "back                359\n",
      "snmpguess           331\n",
      "saint               319\n",
      "mailbomb            293\n",
      "snmpgetattack       178\n",
      "portsweep           157\n",
      "ipsweep             141\n",
      "httptunnel          133\n",
      "nmap                 73\n",
      "pod                  41\n",
      "buffer_overflow      20\n",
      "multihop             18\n",
      "named                17\n",
      "ps                   15\n",
      "sendmail             14\n",
      "rootkit              13\n",
      "xterm                13\n",
      "teardrop             12\n",
      "xlock                 9\n",
      "land                  7\n",
      "xsnoop                4\n",
      "ftp_write             3\n",
      "worm                  2\n",
      "loadmodule            2\n",
      "perl                  2\n",
      "sqlattack             2\n",
      "udpstorm              2\n",
      "phf                   2\n",
      "imap                  1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Label distribution Training set:')\n",
    "print(df['label'].value_counts())\n",
    "print()\n",
    "print('Label distribution Test set:')\n",
    "print(df_test['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a60cac1e-11a7-4f8c-aeda-1e748924034c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:\n",
      "Feature 'protocol_type' has 3 categories\n",
      "Feature 'service' has 70 categories\n",
      "Feature 'flag' has 11 categories\n",
      "Feature 'label' has 23 categories\n",
      "\n",
      "Distribution of categories in service:\n",
      "service\n",
      "http        40338\n",
      "private     21853\n",
      "domain_u     9043\n",
      "smtp         7313\n",
      "ftp_data     6860\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Training set:')\n",
    "for col_name in df.columns:\n",
    "    if df[col_name].dtypes == 'object' :\n",
    "        unique_cat = len(df[col_name].unique())\n",
    "        print(\"Feature '{col_name}' has {unique_cat} categories\".format(col_name=col_name, unique_cat=unique_cat))\n",
    "\n",
    "print()\n",
    "print('Distribution of categories in service:')\n",
    "print(df['service'].value_counts().sort_values(ascending=False).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "452226b4-5023-4cdd-8ef2-65ec24a795a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set:\n",
      "Feature 'protocol_type' has 3 categories\n",
      "Feature 'service' has 64 categories\n",
      "Feature 'flag' has 11 categories\n",
      "Feature 'label' has 38 categories\n"
     ]
    }
   ],
   "source": [
    "print('Test set:')\n",
    "for col_name in df_test.columns:\n",
    "    if df_test[col_name].dtypes == 'object' :\n",
    "        unique_cat = len(df_test[col_name].unique())\n",
    "        print(\"Feature '{col_name}' has {unique_cat} categories\".format(col_name=col_name, unique_cat=unique_cat))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac6d11ac-746d-42a5-a049-e4c4e4b73b28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>protocol_type</th>\n",
       "      <th>service</th>\n",
       "      <th>flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tcp</td>\n",
       "      <td>ftp_data</td>\n",
       "      <td>SF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>udp</td>\n",
       "      <td>other</td>\n",
       "      <td>SF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tcp</td>\n",
       "      <td>private</td>\n",
       "      <td>S0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  protocol_type   service flag\n",
       "0           tcp  ftp_data   SF\n",
       "1           udp     other   SF\n",
       "2           tcp   private   S0\n",
       "3           tcp      http   SF\n",
       "4           tcp      http   SF"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "categorical_columns=['protocol_type', 'service', 'flag']\n",
    "\n",
    "df_categorical_values = df[categorical_columns]\n",
    "testdf_categorical_values = df_test[categorical_columns]\n",
    "\n",
    "df_categorical_values.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d6bbb5f-4a70-486d-87df-550338b5d624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Protocol Type\n",
    "unique_protocol_test = sorted(df_test.protocol_type.unique())\n",
    "string1 = 'Protocol_type_'\n",
    "unique_protocol2_test = [string1 + x for x in unique_protocol_test]\n",
    "\n",
    "# Service\n",
    "unique_service_test = sorted(df_test.service.unique())\n",
    "string2 = 'service_'\n",
    "unique_service2_test = [string2 + x for x in unique_service_test]\n",
    "\n",
    "# Flag\n",
    "unique_flag_test = sorted(df_test.flag.unique())\n",
    "string3 = 'flag_'\n",
    "unique_flag2_test = [string3 + str(x) for x in unique_flag_test]\n",
    "\n",
    "# Put together\n",
    "testdumcols = unique_protocol2_test + unique_service2_test + unique_flag2_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "056af3f7-bc52-495d-8bea-a4f0cd4e9610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  protocol_type   service flag\n",
      "0           tcp  ftp_data   SF\n",
      "1           udp     other   SF\n",
      "2           tcp   private   S0\n",
      "3           tcp      http   SF\n",
      "4           tcp      http   SF\n",
      "--------------------\n",
      "   protocol_type  service  flag\n",
      "0              1       20     9\n",
      "1              2       44     9\n",
      "2              1       49     5\n",
      "3              1       24     9\n",
      "4              1       24     9\n"
     ]
    }
   ],
   "source": [
    "df_categorical_values_enc=df_categorical_values.apply(LabelEncoder().fit_transform)\n",
    "\n",
    "print(df_categorical_values.head())\n",
    "print('--------------------')\n",
    "print(df_categorical_values_enc.head())\n",
    "\n",
    "# test set\n",
    "testdf_categorical_values_enc=testdf_categorical_values.apply(LabelEncoder().fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c514936-2f36-42d3-891b-fdf2d1162e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all values in categorical columns to strings\n",
    "df_categorical_values = df_categorical_values.astype(str)\n",
    "testdf_categorical_values = testdf_categorical_values.astype(str)\n",
    "\n",
    "# Combine categorical values from training and test datasets\n",
    "combined_categorical_values = pd.concat([df_categorical_values, testdf_categorical_values], axis=0)\n",
    "\n",
    "# Fit the OneHotEncoder on the combined data\n",
    "enc = OneHotEncoder(categories='auto')\n",
    "enc.fit(combined_categorical_values)\n",
    "\n",
    "\n",
    "# Manually create the feature names\n",
    "feature_names = []\n",
    "for i, col in enumerate(categorical_columns):\n",
    "    for category in enc.categories_[i]:\n",
    "        feature_names.append(f\"{col}_{category}\")\n",
    "\n",
    "# Transform the training and test sets\n",
    "df_categorical_values_encenc = enc.transform(df_categorical_values)\n",
    "testdf_categorical_values_encenc = enc.transform(testdf_categorical_values)\n",
    "\n",
    "# Convert the transformed data into DataFrames\n",
    "df_cat_data = pd.DataFrame(df_categorical_values_encenc.toarray(), columns=feature_names)\n",
    "testdf_cat_data = pd.DataFrame(testdf_categorical_values_encenc.toarray(), columns=feature_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "caa59c07-9353-4da8-872d-b8d881e31741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>protocol_type_icmp</th>\n",
       "      <th>protocol_type_tcp</th>\n",
       "      <th>protocol_type_udp</th>\n",
       "      <th>service_IRC</th>\n",
       "      <th>service_X11</th>\n",
       "      <th>service_Z39_50</th>\n",
       "      <th>service_aol</th>\n",
       "      <th>service_auth</th>\n",
       "      <th>service_bgp</th>\n",
       "      <th>service_courier</th>\n",
       "      <th>...</th>\n",
       "      <th>flag_REJ</th>\n",
       "      <th>flag_RSTO</th>\n",
       "      <th>flag_RSTOS0</th>\n",
       "      <th>flag_RSTR</th>\n",
       "      <th>flag_S0</th>\n",
       "      <th>flag_S1</th>\n",
       "      <th>flag_S2</th>\n",
       "      <th>flag_S3</th>\n",
       "      <th>flag_SF</th>\n",
       "      <th>flag_SH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   protocol_type_icmp  protocol_type_tcp  protocol_type_udp  service_IRC  \\\n",
       "0                 0.0                1.0                0.0          0.0   \n",
       "1                 0.0                0.0                1.0          0.0   \n",
       "2                 0.0                1.0                0.0          0.0   \n",
       "3                 0.0                1.0                0.0          0.0   \n",
       "4                 0.0                1.0                0.0          0.0   \n",
       "\n",
       "   service_X11  service_Z39_50  service_aol  service_auth  service_bgp  \\\n",
       "0          0.0             0.0          0.0           0.0          0.0   \n",
       "1          0.0             0.0          0.0           0.0          0.0   \n",
       "2          0.0             0.0          0.0           0.0          0.0   \n",
       "3          0.0             0.0          0.0           0.0          0.0   \n",
       "4          0.0             0.0          0.0           0.0          0.0   \n",
       "\n",
       "   service_courier  ...  flag_REJ  flag_RSTO  flag_RSTOS0  flag_RSTR  flag_S0  \\\n",
       "0              0.0  ...       0.0        0.0          0.0        0.0      0.0   \n",
       "1              0.0  ...       0.0        0.0          0.0        0.0      0.0   \n",
       "2              0.0  ...       0.0        0.0          0.0        0.0      1.0   \n",
       "3              0.0  ...       0.0        0.0          0.0        0.0      0.0   \n",
       "4              0.0  ...       0.0        0.0          0.0        0.0      0.0   \n",
       "\n",
       "   flag_S1  flag_S2  flag_S3  flag_SF  flag_SH  \n",
       "0      0.0      0.0      0.0      1.0      0.0  \n",
       "1      0.0      0.0      0.0      1.0      0.0  \n",
       "2      0.0      0.0      0.0      0.0      0.0  \n",
       "3      0.0      0.0      0.0      1.0      0.0  \n",
       "4      0.0      0.0      0.0      1.0      0.0  \n",
       "\n",
       "[5 rows x 84 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0d3bf8c-7da8-4c73-82d0-893e141e74fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125973, 39)\n",
      "(22544, 39)\n",
      "Index(['duration', 'src_bytes', 'dst_bytes', 'land', 'wrong_fragment',\n",
      "       'urgent', 'hot', 'num_failed_logins', 'logged_in', 'num_compromised',\n",
      "       'root_shell', 'su_attempted', 'num_root', 'num_file_creations',\n",
      "       'num_shells', 'num_access_files', 'num_outbound_cmds', 'is_host_login',\n",
      "       'is_guest_login', 'count', 'srv_count', 'serror_rate',\n",
      "       'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate',\n",
      "       'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count',\n",
      "       'dst_host_srv_count', 'dst_host_same_srv_rate',\n",
      "       'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate',\n",
      "       'dst_host_srv_diff_host_rate', 'dst_host_serror_rate',\n",
      "       'dst_host_srv_serror_rate', 'dst_host_rerror_rate',\n",
      "       'dst_host_srv_rerror_rate', 'label'],\n",
      "      dtype='object')\n",
      "Index(['duration', 'src_bytes', 'dst_bytes', 'land', 'wrong_fragment',\n",
      "       'urgent', 'hot', 'num_failed_logins', 'logged_in', 'num_compromised',\n",
      "       'root_shell', 'su_attempted', 'num_root', 'num_file_creations',\n",
      "       'num_shells', 'num_access_files', 'num_outbound_cmds', 'is_host_login',\n",
      "       'is_guest_login', 'count', 'srv_count', 'serror_rate',\n",
      "       'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate',\n",
      "       'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count',\n",
      "       'dst_host_srv_count', 'dst_host_same_srv_rate',\n",
      "       'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate',\n",
      "       'dst_host_srv_diff_host_rate', 'dst_host_serror_rate',\n",
      "       'dst_host_srv_serror_rate', 'dst_host_rerror_rate',\n",
      "       'dst_host_srv_rerror_rate', 'label'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Identify unique 'service' values in training and test sets\n",
    "trainservice = set(df)\n",
    "testservice = set(df_test)\n",
    "\n",
    "# Find the differences\n",
    "difference = list(trainservice - testservice)\n",
    "\n",
    "# Prepend 'service_' to the differing values\n",
    "# string = 'service_'\n",
    "# difference = [string + x for x in difference]\n",
    "\n",
    "# Add missing columns to the test data and initialize them with 0\n",
    "for col in difference:\n",
    "    df_test[col] = 0\n",
    "\n",
    "df.drop(['flag', 'protocol_type', 'service'], axis=1, inplace=True)\n",
    "df_test.drop(['flag', 'protocol_type', 'service'], axis=1, inplace=True)\n",
    "\n",
    "print(df.shape)\n",
    "print(df_test.shape)\n",
    "print(df.columns)\n",
    "print(df_test.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d805f85-1c4b-4899-a3a4-164ae892027b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "labeldf=df['label']\n",
    "labeldf_test=df_test['label']\n",
    "\n",
    "\n",
    "# change the label column\n",
    "newlabeldf=labeldf.replace({ 'normal' : 0, 'neptune' : 1 ,'back': 1, 'land': 1, 'pod': 1, 'smurf': 1, 'teardrop': 1,'mailbomb': 1, 'apache2': 1, 'processtable': 1, 'udpstorm': 1, 'worm': 1,\n",
    "                           'ipsweep' : 2,'nmap' : 2,'portsweep' : 2,'satan' : 2,'mscan' : 2,'saint' : 2\n",
    "                           ,'ftp_write': 3,'guess_passwd': 3,'imap': 3,'multihop': 3,'phf': 3,'spy': 3,'warezclient': 3,'warezmaster': 3,'sendmail': 3,'named': 3,'snmpgetattack': 3,'snmpguess': 3,'xlock': 3,'xsnoop': 3,'httptunnel': 3,\n",
    "                           'buffer_overflow': 4,'loadmodule': 4,'perl': 4,'rootkit': 4,'ps': 4,'sqlattack': 4,'xterm': 4})\n",
    "newlabeldf_test=labeldf_test.replace({ 'normal' : 0, 'neptune' : 1 ,'back': 1, 'land': 1, 'pod': 1, 'smurf': 1, 'teardrop': 1,'mailbomb': 1, 'apache2': 1, 'processtable': 1, 'udpstorm': 1, 'worm': 1,\n",
    "                           'ipsweep' : 2,'nmap' : 2,'portsweep' : 2,'satan' : 2,'mscan' : 2,'saint' : 2\n",
    "                           ,'ftp_write': 3,'guess_passwd': 3,'imap': 3,'multihop': 3,'phf': 3,'spy': 3,'warezclient': 3,'warezmaster': 3,'sendmail': 3,'named': 3,'snmpgetattack': 3,'snmpguess': 3,'xlock': 3,'xsnoop': 3,'httptunnel': 3,\n",
    "                           'buffer_overflow': 4,'loadmodule': 4,'perl': 4,'rootkit': 4,'ps': 4,'sqlattack': 4,'xterm': 4})\n",
    "\n",
    "\n",
    "\n",
    "# put the new label column back\n",
    "df['label'] = newlabeldf\n",
    "df_test['label'] = newlabeldf_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "33de259e-f41d-4e4f-8946-9bebcccef36a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "Dimensions of filtered data: (125973, 39)\n",
      "\n",
      "Test:\n",
      "Dimensions of filtered test data: (22544, 39)\n"
     ]
    }
   ],
   "source": [
    "# Define labels to be dropped\n",
    "to_drop_labels = [0, 1, 2, 3, 4]\n",
    "\n",
    "# Filter out rows with labels to be dropped\n",
    "filtered_df = df[df['label'].isin(to_drop_labels)]\n",
    "filtered_df_test = df_test[df_test['label'].isin(to_drop_labels)]\n",
    "\n",
    "print('Train:')\n",
    "print('Dimensions of filtered data:', filtered_df.shape)\n",
    "print()\n",
    "print('Test:')\n",
    "print('Dimensions of filtered test data:', filtered_df_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40ff4522-2fcf-430c-b365-f7ea680deed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = filtered_df.drop('label', axis=1)\n",
    "Y = filtered_df.label\n",
    "\n",
    "X_test = filtered_df_test.drop('label', axis=1)\n",
    "Y_test = filtered_df_test.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5404c8b4-3d86-479c-a52e-9f300689f02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "colNames=list(X)\n",
    "colNames_test=list(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4897309f-e9fc-4ee6-a5ec-6e9e2a6690a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the indices\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "testdf_cat_data = testdf_cat_data.reset_index(drop=True)\n",
    "\n",
    "# Concatenate X_test and testdf_cat_data\n",
    "X_test = pd.concat([X_test, testdf_cat_data], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ace9abc6-1316-49ac-b3de-12a38faa43a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now you can concatenate without considering indices\n",
    "X = pd.concat([X.reset_index(drop=True), df_cat_data.reset_index(drop=True)], axis=1)\n",
    "X_test = pd.concat([X_test.reset_index(drop=True), testdf_cat_data.reset_index(drop=True)], axis=1)\n",
    "\n",
    "\n",
    "# Reset the index of df_cat_data\n",
    "df_cat_data = df_cat_data.reset_index(drop=True)\n",
    "\n",
    "# Do the same for the test set\n",
    "testdf_cat_data = testdf_cat_data.reset_index(drop=True)\n",
    "\n",
    "# Now you can concatenate without overlapping indices\n",
    "X = pd.concat([X, df_cat_data], axis=1)\n",
    "X_test = pd.concat([X_test, testdf_cat_data], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "684a150e-25f7-4379-bf53-e3282d5f5705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformed_duration          NaN\n",
      "transformed_src_bytes         NaN\n",
      "transformed_dst_bytes         NaN\n",
      "transformed_land              NaN\n",
      "transformed_wrong_fragment    NaN\n",
      "                             ... \n",
      "cat_flag_S1                   0.0\n",
      "cat_flag_S2                   0.0\n",
      "cat_flag_S3                   0.0\n",
      "cat_flag_SF                   0.0\n",
      "cat_flag_SH                   0.0\n",
      "Length: 2654, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(X.std(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "21d9a71f-e00c-4ee1-9672-9b5e82d3d236",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'selected_feature_indices' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m all_feature_names \u001b[38;5;241m=\u001b[39m transformed_columns \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(df_cat_data\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Get the names of selected features\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m selected_feature_names \u001b[38;5;241m=\u001b[39m [all_feature_names[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[43mselected_feature_indices\u001b[49m]\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Print the names of selected features\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSelected feature names:\u001b[39m\u001b[38;5;124m\"\u001b[39m, selected_feature_names)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'selected_feature_indices' is not defined"
     ]
    }
   ],
   "source": [
    "# Get the column names from the original DataFrame\n",
    "original_columns = filtered_df.drop('label', axis=1).columns\n",
    "\n",
    "# Create new column names for the transformed data\n",
    "transformed_columns = [f\"transformed_{col}\" for col in original_columns]\n",
    "\n",
    "# Combine the original and one-hot encoded feature names\n",
    "all_feature_names = transformed_columns + list(df_cat_data.columns)\n",
    "\n",
    "# Get the names of selected features\n",
    "selected_feature_names = [all_feature_names[i] for i in selected_feature_indices]\n",
    "\n",
    "# Print the names of selected features\n",
    "print(\"Selected feature names:\", selected_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "755dd177-c440-4271-a46b-3a7b29646231",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[73], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m X_new_chi2 \u001b[38;5;241m=\u001b[39m selector_chi2\u001b[38;5;241m.\u001b[39mfit_transform(X_new, Y)\n\u001b[0;32m     10\u001b[0m colindex3 \u001b[38;5;241m=\u001b[39m selector_chi2\u001b[38;5;241m.\u001b[39mget_support(indices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 11\u001b[0m colname3 \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mcolNames\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcolindex3\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     12\u001b[0m colname3\n",
      "Cell \u001b[1;32mIn[73], line 11\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      9\u001b[0m X_new_chi2 \u001b[38;5;241m=\u001b[39m selector_chi2\u001b[38;5;241m.\u001b[39mfit_transform(X_new, Y)\n\u001b[0;32m     10\u001b[0m colindex3 \u001b[38;5;241m=\u001b[39m selector_chi2\u001b[38;5;241m.\u001b[39mget_support(indices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 11\u001b[0m colname3 \u001b[38;5;241m=\u001b[39m [\u001b[43mcolNames\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m colindex3]\n\u001b[0;32m     12\u001b[0m colname3\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "# Scale the input features to ensure they are non-negative\n",
    "scaler = MinMaxScaler()\n",
    "X_new = scaler.fit_transform(X)\n",
    "selector_chi2 = SelectKBest(chi2, k=20)\n",
    "\n",
    "X_new_chi2 = selector_chi2.fit_transform(X_new, Y)\n",
    "colindex3 = selector_chi2.get_support(indices=True)\n",
    "colname3 = [colNames[i] for i in colindex3]\n",
    "colname3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f771d426-bc4b-49b5-bc43-3c3404a61a4e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m selector_mi \u001b[38;5;241m=\u001b[39m SelectKBest(mutual_info_regression, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)  \u001b[38;5;66;03m# Select the top 20 features based on mutual information\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Fit and transform the data for feature selection based on mutual information\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m X_new_mi \u001b[38;5;241m=\u001b[39m selector_mi\u001b[38;5;241m.\u001b[39mfit_transform(\u001b[43mX\u001b[49m, Y)\n\u001b[0;32m      8\u001b[0m colindex5 \u001b[38;5;241m=\u001b[39m selector_mi\u001b[38;5;241m.\u001b[39mget_support(indices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      9\u001b[0m colname5 \u001b[38;5;241m=\u001b[39m [colNames[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m colindex5]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, mutual_info_regression\n",
    "\n",
    "# Create a SelectKBest instance with mutual information\n",
    "selector_mi = SelectKBest(mutual_info_regression, k=20)  # Select the top 20 features based on mutual information\n",
    "\n",
    "# Fit and transform the data for feature selection based on mutual information\n",
    "X_new_mi = selector_mi.fit_transform(X, Y)\n",
    "colindex5 = selector_mi.get_support(indices=True)\n",
    "colname5 = [colNames[i] for i in colindex5]\n",
    "colname5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54a6fee7-497b-4489-8797-14b2da8a2a34",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m selector_lasso \u001b[38;5;241m=\u001b[39m SelectFromModel(lasso, max_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)  \u001b[38;5;66;03m# Select only 20 features\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Fit and transform the data for DoS\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m X_new \u001b[38;5;241m=\u001b[39m selector_lasso\u001b[38;5;241m.\u001b[39mfit_transform(\u001b[43mX\u001b[49m, Y)\n\u001b[0;32m     12\u001b[0m colindex4 \u001b[38;5;241m=\u001b[39m selector_lasso\u001b[38;5;241m.\u001b[39mget_support(indices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     13\u001b[0m colname4 \u001b[38;5;241m=\u001b[39m [colNames[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m colindex4]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# Create a Lasso model for feature selection\n",
    "lasso = Lasso(alpha=0.001)  # You can adjust the alpha parameter for regularization strength\n",
    "\n",
    "# Use SelectFromModel to select features based on Lasso coefficients\n",
    "selector_lasso = SelectFromModel(lasso, max_features=20)  # Select only 20 features\n",
    "\n",
    "# Fit and transform the data for DoS\n",
    "X_new = selector_lasso.fit_transform(X, Y)\n",
    "colindex4 = selector_lasso.get_support(indices=True)\n",
    "colname4 = [colNames[i] for i in colindex4]\n",
    "colname4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e1720be-59ef-4017-a0f6-e4a6c56b5dd2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'colname1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m common_numbers\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Example usage:\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m list1 \u001b[38;5;241m=\u001b[39m \u001b[43mcolname1\u001b[49m\n\u001b[0;32m     16\u001b[0m list2 \u001b[38;5;241m=\u001b[39m colname2\n\u001b[0;32m     17\u001b[0m list3 \u001b[38;5;241m=\u001b[39m colname3\n",
      "\u001b[1;31mNameError\u001b[0m: name 'colname1' is not defined"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def common_in_three_or_more(lists):\n",
    "    # Count occurrences of each number across all lists\n",
    "    count = Counter()\n",
    "    for lst in lists:\n",
    "        count.update(set(lst))\n",
    "\n",
    "    # Select numbers that are common in at least three lists\n",
    "    common_numbers = [num for num, freq in count.items() if freq >= 3]\n",
    "\n",
    "    return common_numbers\n",
    "\n",
    "# Example usage:\n",
    "list1 = colname1\n",
    "list2 = colname2\n",
    "list3 = colname3\n",
    "list4 = colname4\n",
    "list5 = colname5\n",
    "\n",
    "\n",
    "lists = [list1, list2, list3, list4, list5]\n",
    "\n",
    "result = common_in_three_or_more(lists)\n",
    "print(\"Numbers common in at least three lists:\",result)\n",
    "print(len(result))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "baa0e9fb-1043-4961-ac2a-262c9684453c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m l\u001b[38;5;241m=\u001b[39m[]\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[43mresult\u001b[49m:\n\u001b[0;32m      3\u001b[0m    l\u001b[38;5;241m.\u001b[39mappend(colNames\u001b[38;5;241m.\u001b[39mindex(i))\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(l)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'result' is not defined"
     ]
    }
   ],
   "source": [
    "l=[]\n",
    "for i in result:\n",
    "   l.append(colNames.index(i))\n",
    "\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44418684-f4dd-4602-add5-86ee73ef6c66",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 11\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# clf = RandomForestClassifier(n_estimators=10,n_jobs=2)\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# rfe = RFE(estimator=clf, n_features_to_select=12, step=1)\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# rfe.fit(X, Y.astype(int))\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# X_rfe=rfe.transform(X)\u001b[39;00m\n\u001b[0;32m     10\u001b[0m colindex\u001b[38;5;241m=\u001b[39ml\n\u001b[1;32m---> 11\u001b[0m colname\u001b[38;5;241m=\u001b[39m \u001b[43mresult\u001b[49m\n\u001b[0;32m     13\u001b[0m selected_features \u001b[38;5;241m=\u001b[39m [X[:, index] \u001b[38;5;28;01mfor\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m colindex]\n\u001b[0;32m     14\u001b[0m X_rfe \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcolumn_stack(selected_features)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'result' is not defined"
     ]
    }
   ],
   "source": [
    "# from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "# clf = RandomForestClassifier(n_estimators=10,n_jobs=2)\n",
    "# rfe = RFE(estimator=clf, n_features_to_select=12, step=1)\n",
    "# rfe.fit(X, Y.astype(int))\n",
    "# X_rfe=rfe.transform(X)\n",
    "\n",
    "colindex=l\n",
    "colname= result\n",
    "\n",
    "selected_features = [X[:, index] for index in colindex]\n",
    "X_rfe = np.column_stack(selected_features)\n",
    "\n",
    "print(colindex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afd270a7-b34a-401f-9c85-c07d707b7b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATURES SELECTED BY ENSEMBLED METHOD \n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'colname' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFEATURES SELECTED BY ENSEMBLED METHOD \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFeatures selected for DoS:\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[43mcolname\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'colname' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"FEATURES SELECTED BY ENSEMBLED METHOD \\n\\n\")\n",
    "print('Features selected for DoS:',colname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c5d6c5e-5c7c-494b-b3ca-ef9ed6b87c13",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_rfe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mX_rfe\u001b[49m\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_rfe' is not defined"
     ]
    }
   ],
   "source": [
    "print(X_rfe.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ffba6eb-2544-47a6-8fcc-fb7fc545ebb4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_rfe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m clf_rf\u001b[38;5;241m=\u001b[39mRandomForestClassifier(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m clf_rf\u001b[38;5;241m.\u001b[39mfit(\u001b[43mX_rfe\u001b[49m, Y\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_rfe' is not defined"
     ]
    }
   ],
   "source": [
    "clf_rf=RandomForestClassifier(n_estimators=10,n_jobs=1)\n",
    "clf_rf.fit(X_rfe, Y.astype(int))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5462d0b7-5e7c-4648-bbaa-4752a7a2b1c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m Y_pred2\u001b[38;5;241m=\u001b[39mclf_rf\u001b[38;5;241m.\u001b[39mpredict(\u001b[43mX_test2\u001b[49m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Create confusion matrix\u001b[39;00m\n\u001b[0;32m      3\u001b[0m pd\u001b[38;5;241m.\u001b[39mcrosstab(Y_test, Y_pred2, rownames\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mActual attacks\u001b[39m\u001b[38;5;124m'\u001b[39m], colnames\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredicted attacks\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_test2' is not defined"
     ]
    }
   ],
   "source": [
    "Y_pred2=clf_rf.predict(X_test2)\n",
    "# Create confusion matrix\n",
    "pd.crosstab(Y_test, Y_pred2, rownames=['Actual attacks'], colnames=['Predicted attacks'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5cae95a-a177-4712-9073-c014f4b3764e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e509c96a-87f7-43e5-b285-ac559f81cf37",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m precision_score, recall_score, f1_score\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Compute metrics with appropriate averaging\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m cross_val_score(clf_rf, \u001b[43mX_test2\u001b[49m, Y_test, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy: \u001b[39m\u001b[38;5;132;01m%0.5f\u001b[39;00m\u001b[38;5;124m (+/- \u001b[39m\u001b[38;5;132;01m%0.5f\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (accuracy\u001b[38;5;241m.\u001b[39mmean(), accuracy\u001b[38;5;241m.\u001b[39mstd() \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m))\n\u001b[0;32m      7\u001b[0m precision \u001b[38;5;241m=\u001b[39m cross_val_score(clf_rf, X_test2, Y_test, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecision_macro\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_test2' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Compute metrics with appropriate averaging\n",
    "accuracy = cross_val_score(clf_rf, X_test2, Y_test, cv=10, scoring='accuracy')\n",
    "print(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))\n",
    "\n",
    "precision = cross_val_score(clf_rf, X_test2, Y_test, cv=10, scoring='precision_macro')\n",
    "print(\"Precision: %0.5f (+/- %0.5f)\" % (precision.mean(), precision.std() * 2))\n",
    "\n",
    "recall = cross_val_score(clf_rf, X_test2, Y_test, cv=10, scoring='recall_macro')\n",
    "print(\"Recall: %0.5f (+/- %0.5f)\" % (recall.mean(), recall.std() * 2))\n",
    "\n",
    "f1 = cross_val_score(clf_rf, X_test2, Y_test, cv=10, scoring='f1_macro')\n",
    "print(\"F-measure: %0.5f (+/- %0.5f)\" % (f1.mean(), f1.std() * 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c72a71c-ddf1-497d-9c82-41b17c5a3f77",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Calculate ROC curve for each class\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m Y_probs \u001b[38;5;241m=\u001b[39m clf_rf\u001b[38;5;241m.\u001b[39mpredict_proba(\u001b[43mX_test2\u001b[49m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Compute ROC curve and ROC area for each class\u001b[39;00m\n\u001b[0;32m      8\u001b[0m fpr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_test2' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate ROC curve for each class\n",
    "Y_probs = clf_rf.predict_proba(X_test2)\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(len(Y_probs[0])):\n",
    "    fpr[i], tpr[i], _ = roc_curve((Y_test == i).astype(int), Y_probs[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot ROC curve for each class\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i in range(len(Y_probs[0])):\n",
    "    plt.plot(fpr[i], tpr[i], label='ROC curve (class {}) (area = {:0.2f})'.format(i, roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')  # Plot diagonal line\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17b187fc-fd1f-4db1-85d2-3d209fc237bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_rfe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mneighbors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KNeighborsClassifier\n\u001b[0;32m      2\u001b[0m clf_KNN\u001b[38;5;241m=\u001b[39mKNeighborsClassifier()\n\u001b[1;32m----> 3\u001b[0m clf_KNN\u001b[38;5;241m.\u001b[39mfit(\u001b[43mX_rfe\u001b[49m, Y\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_rfe' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf_KNN=KNeighborsClassifier()\n",
    "clf_KNN.fit(X_rfe, Y.astype(int))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9020bb8d-cead-44cf-8f0f-b6667068b9f1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m Y_pred2\u001b[38;5;241m=\u001b[39mclf_KNN\u001b[38;5;241m.\u001b[39mpredict(\u001b[43mX_test2\u001b[49m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Create confusion matrix\u001b[39;00m\n\u001b[0;32m      3\u001b[0m pd\u001b[38;5;241m.\u001b[39mcrosstab(Y_test, Y_pred2, rownames\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mActual attacks\u001b[39m\u001b[38;5;124m'\u001b[39m], colnames\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredicted attacks\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_test2' is not defined"
     ]
    }
   ],
   "source": [
    "Y_pred2=clf_KNN.predict(X_test2)\n",
    "# Create confusion matrix\n",
    "pd.crosstab(Y_test, Y_pred2, rownames=['Actual attacks'], colnames=['Predicted attacks'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56931c80-c204-4887-b02f-1832db47b855",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m precision_score, recall_score, f1_score\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Compute metrics with appropriate averaging\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m cross_val_score(clf_KNN, \u001b[43mX_test2\u001b[49m, Y_test, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy: \u001b[39m\u001b[38;5;132;01m%0.5f\u001b[39;00m\u001b[38;5;124m (+/- \u001b[39m\u001b[38;5;132;01m%0.5f\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (accuracy\u001b[38;5;241m.\u001b[39mmean(), accuracy\u001b[38;5;241m.\u001b[39mstd() \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m))\n\u001b[0;32m      7\u001b[0m precision \u001b[38;5;241m=\u001b[39m cross_val_score(clf_KNN, X_test2, Y_test, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecision_macro\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_test2' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Compute metrics with appropriate averaging\n",
    "accuracy = cross_val_score(clf_KNN, X_test2, Y_test, cv=10, scoring='accuracy')\n",
    "print(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))\n",
    "\n",
    "precision = cross_val_score(clf_KNN, X_test2, Y_test, cv=10, scoring='precision_macro')\n",
    "print(\"Precision: %0.5f (+/- %0.5f)\" % (precision.mean(), precision.std() * 2))\n",
    "\n",
    "recall = cross_val_score(clf_KNN, X_test2, Y_test, cv=10, scoring='recall_macro')\n",
    "print(\"Recall: %0.5f (+/- %0.5f)\" % (recall.mean(), recall.std() * 2))\n",
    "\n",
    "f1 = cross_val_score(clf_KNN, X_test2, Y_test, cv=10, scoring='f1_macro')\n",
    "print(\"F-measure: %0.5f (+/- %0.5f)\" % (f1.mean(), f1.std() * 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa2ef8aa-26b7-49bd-9eab-7fc5f33645fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Calculate ROC curve for each class\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m Y_probs \u001b[38;5;241m=\u001b[39m clf_KNN\u001b[38;5;241m.\u001b[39mpredict_proba(\u001b[43mX_test2\u001b[49m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Compute ROC curve and ROC area for each class\u001b[39;00m\n\u001b[0;32m      8\u001b[0m fpr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_test2' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate ROC curve for each class\n",
    "Y_probs = clf_KNN.predict_proba(X_test2)\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(len(Y_probs[0])):\n",
    "    fpr[i], tpr[i], _ = roc_curve((Y_test == i).astype(int), Y_probs[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot ROC curve for each class\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i in range(len(Y_probs[0])):\n",
    "    plt.plot(fpr[i], tpr[i], label='ROC curve (class {}) (area = {:0.2f})'.format(i, roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')  # Plot diagonal line\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1accd332-8fb1-4033-8d81-a6b5033ca05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "clf_SVM=SVC(kernel='linear', C=1.0, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "08b648ce-e066-40b2-81b7-8b72088ddee0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_rfe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m clf_SVM\u001b[38;5;241m.\u001b[39mfit(\u001b[43mX_rfe\u001b[49m, Y\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_rfe' is not defined"
     ]
    }
   ],
   "source": [
    "clf_SVM.fit(X_rfe, Y.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "af5bf314-1ad5-484e-9534-a2800a01764f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m Y_pred2\u001b[38;5;241m=\u001b[39mclf_SVM\u001b[38;5;241m.\u001b[39mpredict(\u001b[43mX_test2\u001b[49m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Create confusion matrix\u001b[39;00m\n\u001b[0;32m      4\u001b[0m pd\u001b[38;5;241m.\u001b[39mcrosstab(Y_test, Y_pred2, rownames\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mActual attacks\u001b[39m\u001b[38;5;124m'\u001b[39m], colnames\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredicted attacks\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_test2' is not defined"
     ]
    }
   ],
   "source": [
    "Y_pred2=clf_SVM.predict(X_test2)\n",
    "\n",
    "# Create confusion matrix\n",
    "pd.crosstab(Y_test, Y_pred2, rownames=['Actual attacks'], colnames=['Predicted attacks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c4b8b926-3e78-4b5f-a8e2-c34fdeccc17a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Y_pred2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mY_pred2\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Y_pred2' is not defined"
     ]
    }
   ],
   "source": [
    "Y_pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d7365478-0dbd-4082-8758-ee296cfec98f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, precision_score, recall_score, f1_score\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Calculate accuracy\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(\u001b[43mY_test\u001b[49m, Y_pred2)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m, accuracy)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Calculate precision\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Y_test' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(Y_test, Y_pred2)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "# Calculate precision\n",
    "precision = precision_score(Y_test, Y_pred2, average='weighted')\n",
    "print(\"Precision:\", precision)\n",
    "recall = recall_score(Y_test, Y_pred2, average='weighted')\n",
    "\n",
    "print(\"Recall:\", recall)\n",
    "f1 = f1_score(Y_test, Y_pred2, average='weighted')\n",
    "\n",
    "print(\"F1-score:\", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "918bce25-f4c5-48fa-91a8-3ece4c05d233",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classification_report\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(\u001b[43mY_test\u001b[49m, Y_pred2))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Y_test' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test, Y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ff190d16-e238-43fc-b75c-50b8ddca62f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 7\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Fit the SVM classifier\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Predict probabilities for each class\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m Y_probs \u001b[38;5;241m=\u001b[39m clf_SVM\u001b[38;5;241m.\u001b[39mdecision_function(\u001b[43mX_test2\u001b[49m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Compute ROC curve and ROC area for each class\u001b[39;00m\n\u001b[0;32m     10\u001b[0m fpr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_test2' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Fit the SVM classifier\n",
    "\n",
    "# Predict probabilities for each class\n",
    "Y_probs = clf_SVM.decision_function(X_test2)\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(len(Y_probs[0])):\n",
    "    fpr[i], tpr[i], _ = roc_curve((Y_test == i).astype(int), Y_probs[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot ROC curve for each class\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i in range(len(Y_probs[0])):\n",
    "    plt.plot(fpr[i], tpr[i], label='ROC curve (class {}) (area = {:0.2f})'.format(i, roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')  # Plot diagonal line\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d6d6f2c4-77c9-460d-8902-1004d01f5067",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Create Gaussian Naive Bayes classifiers\n",
    "clf_NB = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b864a0d6-7d6f-4e93-b396-b9de7d523907",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_rfe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m clf_NB\u001b[38;5;241m.\u001b[39mfit(\u001b[43mX_rfe\u001b[49m, Y\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_rfe' is not defined"
     ]
    }
   ],
   "source": [
    "clf_NB.fit(X_rfe, Y.astype(int))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "187e4193-596b-4957-a9e6-f56eb731eeb2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m Y_pred2 \u001b[38;5;241m=\u001b[39m clf_NB\u001b[38;5;241m.\u001b[39mpredict(\u001b[43mX_test2\u001b[49m)\n\u001b[0;32m      2\u001b[0m pd\u001b[38;5;241m.\u001b[39mcrosstab(Y_test, Y_pred2, rownames\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mActual attacks\u001b[39m\u001b[38;5;124m'\u001b[39m], colnames\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredicted attacks\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_test2' is not defined"
     ]
    }
   ],
   "source": [
    "Y_pred2 = clf_NB.predict(X_test2)\n",
    "pd.crosstab(Y_test, Y_pred2, rownames=['Actual attacks'], colnames=['Predicted attacks'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "26c0dc9f-3cfa-4646-bd3e-abc15d347b16",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, precision_score, recall_score, f1_score\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Calculate accuracy\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(\u001b[43mY_test\u001b[49m, Y_pred2)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m, accuracy)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Calculate precision\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Y_test' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(Y_test, Y_pred2)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "# Calculate precision\n",
    "precision = precision_score(Y_test, Y_pred2, average='weighted')\n",
    "print(\"Precision:\", precision)\n",
    "recall = recall_score(Y_test, Y_pred2, average='weighted')\n",
    "\n",
    "print(\"Recall:\", recall)\n",
    "f1 = f1_score(Y_test, Y_pred2, average='weighted')\n",
    "\n",
    "print(\"F1-score:\", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c4229ba6-4233-45f4-8de3-854edc9607a2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classification_report\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(\u001b[43mY_test\u001b[49m, Y_pred2))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Y_test' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test, Y_pred2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9cbb0e89-53c7-404d-9083-03b5d0594ed0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 11\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Instantiate and fit the Naive Bayes classifier\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \n\u001b[0;32m      9\u001b[0m \n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Predict probabilities for each class\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m Y_probs \u001b[38;5;241m=\u001b[39m clf_NB\u001b[38;5;241m.\u001b[39mpredict_proba(\u001b[43mX_test2\u001b[49m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Binarize the labels\u001b[39;00m\n\u001b[0;32m     14\u001b[0m y_test_binarized \u001b[38;5;241m=\u001b[39m label_binarize(Y_test, classes\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39munique(Y_test))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_test2' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import numpy as np\n",
    "\n",
    "# Instantiate and fit the Naive Bayes classifier\n",
    "\n",
    "\n",
    "# Predict probabilities for each class\n",
    "Y_probs = clf_NB.predict_proba(X_test2)\n",
    "\n",
    "# Binarize the labels\n",
    "y_test_binarized = label_binarize(Y_test, classes=np.unique(Y_test))\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "n_classes = len(np.unique(Y_test))\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_binarized[:, i], Y_probs[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot ROC curve for each class\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i in range(n_classes):\n",
    "    plt.plot(fpr[i], tpr[i], label='ROC curve (class {}) (area = {:0.2f})'.format(i, roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')  # Plot diagonal line\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9ccf6310-9cb0-4823-9736-fb8edc21279c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create Logistic Regression classifiers\n",
    "clf_LR = LogisticRegression(random_state=0, max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b0963cbb-e473-4f8f-bc2a-81401a21d096",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_rfe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m clf_LR\u001b[38;5;241m.\u001b[39mfit(\u001b[43mX_rfe\u001b[49m, Y\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_rfe' is not defined"
     ]
    }
   ],
   "source": [
    "clf_LR.fit(X_rfe, Y.astype(int))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7293b5c7-8b97-4d33-aa35-19bb30cb65b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m Y_pred2 \u001b[38;5;241m=\u001b[39m clf_LR\u001b[38;5;241m.\u001b[39mpredict(\u001b[43mX_test2\u001b[49m)\n\u001b[0;32m      2\u001b[0m pd\u001b[38;5;241m.\u001b[39mcrosstab(Y_test, Y_pred2, rownames\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mActual attacks\u001b[39m\u001b[38;5;124m'\u001b[39m], colnames\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredicted attacks\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_test2' is not defined"
     ]
    }
   ],
   "source": [
    "Y_pred2 = clf_LR.predict(X_test2)\n",
    "pd.crosstab(Y_test, Y_pred2, rownames=['Actual attacks'], colnames=['Predicted attacks'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5f9d2bc2-11d1-49c4-97ff-941f787a2189",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m precision_score, recall_score, f1_score\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Compute metrics with appropriate averaging\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m cross_val_score(clf_LR, \u001b[43mX_test2\u001b[49m, Y_test, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy: \u001b[39m\u001b[38;5;132;01m%0.5f\u001b[39;00m\u001b[38;5;124m (+/- \u001b[39m\u001b[38;5;132;01m%0.5f\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (accuracy\u001b[38;5;241m.\u001b[39mmean(), accuracy\u001b[38;5;241m.\u001b[39mstd() \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m))\n\u001b[0;32m      7\u001b[0m precision \u001b[38;5;241m=\u001b[39m cross_val_score(clf_LR, X_test2, Y_test, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecision_macro\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_test2' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Compute metrics with appropriate averaging\n",
    "accuracy = cross_val_score(clf_LR, X_test2, Y_test, cv=10, scoring='accuracy')\n",
    "print(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))\n",
    "\n",
    "precision = cross_val_score(clf_LR, X_test2, Y_test, cv=10, scoring='precision_macro')\n",
    "print(\"Precision: %0.5f (+/- %0.5f)\" % (precision.mean(), precision.std() * 2))\n",
    "\n",
    "recall = cross_val_score(clf_LR, X_test2, Y_test, cv=10, scoring='recall_macro')\n",
    "print(\"Recall: %0.5f (+/- %0.5f)\" % (recall.mean(), recall.std() * 2))\n",
    "\n",
    "f1 = cross_val_score(clf_LR, X_test2, Y_test, cv=10, scoring='f1_macro')\n",
    "print(\"F-measure: %0.5f (+/- %0.5f)\" % (f1.mean(), f1.std() * 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "788c1463-fedf-4666-9f08-17b552dacfe5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 7\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Fit the Logistic Regression classifier\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Predict probabilities for each class\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m Y_probs \u001b[38;5;241m=\u001b[39m clf_LR\u001b[38;5;241m.\u001b[39mpredict_proba(\u001b[43mX_test2\u001b[49m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Compute ROC curve and ROC area for each class\u001b[39;00m\n\u001b[0;32m     10\u001b[0m fpr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_test2' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Fit the Logistic Regression classifier\n",
    "\n",
    "# Predict probabilities for each class\n",
    "Y_probs = clf_LR.predict_proba(X_test2)\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(len(Y_probs[0])):\n",
    "    fpr[i], tpr[i], _ = roc_curve((Y_test == i).astype(int), Y_probs[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot ROC curve for each class\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i in range(len(Y_probs[0])):\n",
    "    plt.plot(fpr[i], tpr[i], label='ROC curve (class {}) (area = {:0.2f})'.format(i, roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')  # Plot diagonal line\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e88cf1e7-6ae8-4856-80f8-2444accd42c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize classifiers with probability=True\n",
    "clf_SVM = SVC(probability=True)\n",
    "clf_NB = GaussianNB()\n",
    "clf_LR = LogisticRegression(random_state=0, max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "640a1d85-43ce-4f1e-909f-55d15a29effa",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_rfe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 10\u001b[0m\n\u001b[0;32m      1\u001b[0m clf_voting \u001b[38;5;241m=\u001b[39m VotingClassifier(estimators\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m      2\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m'\u001b[39m, clf_rf),\n\u001b[0;32m      3\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mknn\u001b[39m\u001b[38;5;124m'\u001b[39m, clf_KNN),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      6\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLR\u001b[39m\u001b[38;5;124m'\u001b[39m, clf_LR)\n\u001b[0;32m      7\u001b[0m ], voting\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoft\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Fit the VotingClassifier\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m clf_voting\u001b[38;5;241m.\u001b[39mfit(\u001b[43mX_rfe\u001b[49m, Y\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_rfe' is not defined"
     ]
    }
   ],
   "source": [
    "clf_voting = VotingClassifier(estimators=[\n",
    "    ('rf', clf_rf),\n",
    "    ('knn', clf_KNN),\n",
    "    ('svm', clf_SVM),\n",
    "    ('NB', clf_NB),\n",
    "    ('LR', clf_LR)\n",
    "], voting='soft')\n",
    "\n",
    "# Fit the VotingClassifier\n",
    "clf_voting.fit(X_rfe, Y.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "36d008fa-67c9-41a8-bfa9-b69b518cb931",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "pkl.dump(clf_voting,open(\"finalpro.p\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1ec1208c-c464-4acf-bfef-5d691f361900",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This VotingClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m i\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39masarray(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m      5\u001b[0m i1\u001b[38;5;241m=\u001b[39mi\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m prediction\u001b[38;5;241m=\u001b[39m\u001b[43ml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi1\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_voting.py:364\u001b[0m, in \u001b[0;36mVotingClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    352\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Predict class labels for X.\u001b[39;00m\n\u001b[0;32m    353\u001b[0m \n\u001b[0;32m    354\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[38;5;124;03m        Predicted class labels.\u001b[39;00m\n\u001b[0;32m    363\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 364\u001b[0m     \u001b[43mcheck_is_fitted\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    365\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvoting \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoft\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    366\u001b[0m         maj \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_proba(X), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1461\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m   1458\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not an estimator instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (estimator))\n\u001b[0;32m   1460\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_fitted(estimator, attributes, all_or_any):\n\u001b[1;32m-> 1461\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(msg \u001b[38;5;241m%\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m})\n",
      "\u001b[1;31mNotFittedError\u001b[0m: This VotingClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "l=pkl.load(open(\"finalpro.p\",\"rb\"))\n",
    "# [8, 27, 30, 36, 19, 31, 32, 26, 28, 33, 21, 35, 23, 24, 29, 37, 6, 22, 34, 25]\n",
    "input=(0,0,0.04,1,229,0.06,0,0.06,255,0,0,0,1,1,10,1,0,0,0,0.04)\n",
    "i=np.asarray(input)\n",
    "i1=i.reshape(1,-1)\n",
    "prediction=l.predict(i1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "438a83dc-0cdb-4139-9561-576dcd6383ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prediction' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mprediction\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'prediction' is not defined"
     ]
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a59f7f9d-2f19-40c3-9a09-43d705bcd914",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Predict using the VotingClassifier\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m Y_pred_voting \u001b[38;5;241m=\u001b[39m clf_voting\u001b[38;5;241m.\u001b[39mpredict(\u001b[43mX_test2\u001b[49m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Create confusion matrix\u001b[39;00m\n\u001b[0;32m      5\u001b[0m confusion_matrix_voting \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mcrosstab(Y_test, Y_pred_voting, rownames\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mActual attacks\u001b[39m\u001b[38;5;124m'\u001b[39m], colnames\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredicted attacks\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_test2' is not defined"
     ]
    }
   ],
   "source": [
    "# Predict using the VotingClassifier\n",
    "Y_pred_voting = clf_voting.predict(X_test2)\n",
    "\n",
    "# Create confusion matrix\n",
    "confusion_matrix_voting = pd.crosstab(Y_test, Y_pred_voting, rownames=['Actual attacks'], colnames=['Predicted attacks'])\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(confusion_matrix_voting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cef8573a-cbeb-429b-b248-0d5da210c411",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 9\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Assuming y_true contains the true labels and y_pred contains the predicted labels\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Example:\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# y_true = [0, 1, 1, 0, 1]\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# y_pred = [0, 1, 0, 0, 1]\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Convert lists to numpy arrays for easier manipulation\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m y_true \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[43mY_test\u001b[49m)\n\u001b[0;32m     10\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(Y_pred2)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Find the indices where true positive predictions occur\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Y_test' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming y_true contains the true labels and y_pred contains the predicted labels\n",
    "# Example:\n",
    "# y_true = [0, 1, 1, 0, 1]\n",
    "# y_pred = [0, 1, 0, 0, 1]\n",
    "\n",
    "# Convert lists to numpy arrays for easier manipulation\n",
    "y_true = np.array(Y_test)\n",
    "y_pred = np.array(Y_pred2)\n",
    "\n",
    "# Find the indices where true positive predictions occur\n",
    "tp_indices = np.where((y_true == 1) & (y_pred == 1))[0]\n",
    "\n",
    "print(\"Indices of True Positive Predictions:\", tp_indices)\n",
    "\n",
    "# If you want to extract the corresponding rows from your dataset, assuming your dataset is a numpy array named 'data':\n",
    "tp_rows = df[tp_indices]\n",
    "\n",
    "print(\"Rows corresponding to True Positive Predictions:\")\n",
    "print(tp_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8bf53d5a-17b7-43b2-b1c6-02efd0c997f7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m precision_score, recall_score, f1_score\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Compute metrics with appropriate averaging\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m cross_val_score(clf_voting, \u001b[43mX_test2\u001b[49m, Y_test, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy: \u001b[39m\u001b[38;5;132;01m%0.5f\u001b[39;00m\u001b[38;5;124m (+/- \u001b[39m\u001b[38;5;132;01m%0.5f\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (accuracy\u001b[38;5;241m.\u001b[39mmean(), accuracy\u001b[38;5;241m.\u001b[39mstd() \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m))\n\u001b[0;32m      7\u001b[0m precision \u001b[38;5;241m=\u001b[39m cross_val_score(clf_voting, X_test2, Y_test, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecision_macro\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_test2' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Compute metrics with appropriate averaging\n",
    "accuracy = cross_val_score(clf_voting, X_test2, Y_test, cv=10, scoring='accuracy')\n",
    "print(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))\n",
    "\n",
    "precision = cross_val_score(clf_voting, X_test2, Y_test, cv=10, scoring='precision_macro')\n",
    "print(\"Precision: %0.5f (+/- %0.5f)\" % (precision.mean(), precision.std() * 2))\n",
    "\n",
    "recall = cross_val_score(clf_voting, X_test2, Y_test, cv=10, scoring='recall_macro')\n",
    "print(\"Recall: %0.5f (+/- %0.5f)\" % (recall.mean(), recall.std() * 2))\n",
    "\n",
    "f1 = cross_val_score(clf_voting, X_test2, Y_test, cv=10, scoring='f1_macro')\n",
    "print(\"F-measure: %0.5f (+/- %0.5f)\" % (f1.mean(), f1.std() * 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "427afa74-9931-456e-92d0-bf2fbfd0ff40",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classification_report\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(\u001b[43mY_test\u001b[49m, Y_pred2))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Y_test' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test, Y_pred2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b31ad2fb-1712-4ccc-a6a9-ec5158d4fb29",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m label_binarize\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Predict probabilities for each class\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m Y_probs_voting \u001b[38;5;241m=\u001b[39m clf_voting\u001b[38;5;241m.\u001b[39mpredict_proba(\u001b[43mX_test2\u001b[49m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Binarize the labels\u001b[39;00m\n\u001b[0;32m      9\u001b[0m y_test_binarized \u001b[38;5;241m=\u001b[39m label_binarize(Y_test, classes\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39munique(Y_test))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_test2' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Predict probabilities for each class\n",
    "Y_probs_voting = clf_voting.predict_proba(X_test2)\n",
    "\n",
    "# Binarize the labels\n",
    "y_test_binarized = label_binarize(Y_test, classes=np.unique(Y_test))\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "n_classes = len(np.unique(Y_test))\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_binarized[:, i], Y_probs_voting[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot ROC curve for each class\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i in range(n_classes):\n",
    "    plt.plot(fpr[i], tpr[i], label='ROC curve (class {}) (area = {:0.2f})'.format(i, roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')  # Plot diagonal line\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c13805b-8ade-4fc4-9d26-36bf34157da7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
